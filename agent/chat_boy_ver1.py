#!/usr/bin/env python3
"""
æ™ºèƒ½æ–‡ä»¶åˆ†æåŠ©æ‰‹ï¼ˆæ”¯æŒæ€è€ƒã€è®¡åˆ’ã€å†³ç­–ã€æ‰§è¡Œï¼‰
åŒ…å«å®Œæ•´çš„ Agent æ¶æ„ï¼š
- thinking/plan: æ€è€ƒå¹¶åˆ¶å®šè®¡åˆ’
- decide: å†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨
- act: æ‰§è¡Œå·¥å…·è°ƒç”¨
- observe: è§‚å¯Ÿå·¥å…·æ‰§è¡Œç»“æœ
"""

import os
import operator
from typing import Annotated, Literal, Optional
from typing_extensions import TypedDict
from langgraph.graph import StateGraph, START, END
from langgraph.graph.message import add_messages
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, ToolMessage, AnyMessage
from langchain.tools import tool
from pydantic import SecretStr
from langgraph.checkpoint.memory import MemorySaver

from load_env import API_KEY, BASE_URL

# åˆå§‹åŒ– LLMï¼ˆéæµå¼è¾“å‡ºï¼‰
llm = ChatOpenAI(
    streaming=False,
    api_key=SecretStr(API_KEY),
    base_url=BASE_URL,
    model="gpt-4.1",
    temperature=0
)


# å®šä¹‰å·¥å…·
@tool
def list_directory(directory_path: str = ".") -> str:
    """list file under specific directory
    
    Args:
        directory_path: dir path to be listed, default is current dir: '.'
    
    Returns:
        content list of a directory
    """
    try:
        if not os.path.isabs(directory_path):
            directory_path = os.path.abspath(directory_path)
        
        if not os.path.exists(directory_path):
            return f"Error: dir '{directory_path}' doesn't exist"
        
        if not os.path.isdir(directory_path):
            return f"Error:'{directory_path}' is not a directory"
        
        items = []
        for item in sorted(os.listdir(directory_path)):
            item_path = os.path.join(directory_path, item)
            if os.path.isdir(item_path):
                items.append(f"[dir] {item}/")
            else:
                size = os.path.getsize(item_path)
                items.append(f"[file] {item} ({size} bytes)")
        
        result = f"content of dir '{directory_path}':\n" + "\n".join(items)
        return result
    except Exception as e:
        return f"Error: failed to list directory - {str(e)}"


@tool
def read_file_tool(file_path: str) -> str:
    """read content of certain file
    
    Args:
        file_path: path of target file (absolute or relative path)
    
    Returns:
        file content. if doesn't exist, it is error message.
    """
    try:
        if not os.path.isabs(file_path):
            file_path = os.path.abspath(file_path)
        
        if not os.path.exists(file_path):
            return f"Error: file '{file_path}' doesn't exist"
        
        if not os.path.isfile(file_path):
            return f"Error: file '{file_path}' is not a file"
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            return f"file: '{file_path}' , length: {len(content)}, content:\n\n{content}"
        except UnicodeDecodeError:
            with open(file_path, 'rb') as f:
                content = f.read()
            return f"file '{file_path}' is a binary file with length {len(content)}, cannot displayed as text."
    except Exception as e:
        return f"Error in reading file - {str(e)}"


# ç»‘å®šå·¥å…·åˆ° LLM
tools = [list_directory, read_file_tool]
tools_by_name = {tool.name: tool for tool in tools}
model_with_tools = llm.bind_tools(tools)


class State(TypedDict):
    """Agent çŠ¶æ€"""
    messages: Annotated[list[AnyMessage], operator.add]
    thinking: str  # æ€è€ƒè¿‡ç¨‹
    plan: str  # è®¡åˆ’
    action: Optional[str]  # å½“å‰è¡ŒåŠ¨
    needs_more_info: bool  # æ˜¯å¦éœ€è¦æ›´å¤šä¿¡æ¯


def thinking_node(state: State):
    """æ€è€ƒèŠ‚ç‚¹ï¼šåˆ†æç”¨æˆ·éœ€æ±‚å¹¶åˆ¶å®šè®¡åˆ’"""
    system_prompt = """You are a professional file-analyzing assistant. You need to:
1. Understand the user's request
2. Think about what information you need
3. Make a plan to solve the problem

You have access to these tools:
- list_directory: list the content of a directory
- read_file_tool: read the content of a file

Think step by step about:
- What does the user want?
- What information do I need?
- What tools should I use?
- What is my plan?

Format your thinking and plan clearly."""
    
    # è·å–ç”¨æˆ·æœ€åä¸€æ¡æ¶ˆæ¯
    user_messages = [msg for msg in state["messages"] if isinstance(msg, HumanMessage)]
    last_user_message = user_messages[-1] if user_messages else None
    
    if not last_user_message:
        return {
            "thinking": "No user message found.",
            "plan": "Wait for user input.",
            "action": "wait"
        }
    
    # æ„å»ºæ€è€ƒæç¤ºè¯
    thinking_prompt = f"""User request: {last_user_message.content}

Previous context:
{chr(10).join([f"- {msg.content[:100]}" for msg in state["messages"][-5:-1] if hasattr(msg, 'content')])}

Think about:
1. What is the user asking for?
2. Do I have enough information to answer?
3. What tools do I need to use?
4. What is my step-by-step plan?

Provide your thinking process and plan:"""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=thinking_prompt)
    ]
    
    response = llm.invoke(messages)
    thinking_content = response.content
    
    # æå–æ€è€ƒå’Œè®¡åˆ’
    thinking = thinking_content
    plan = thinking_content  # å¯ä»¥è¿›ä¸€æ­¥è§£æï¼Œè¿™é‡Œç®€åŒ–å¤„ç†
    
    print("\n" + "="*60)
    print("ğŸ¤” THINKING:")
    print("="*60)
    print(thinking_content)
    print("="*60 + "\n")
    
    return {
        "thinking": thinking_content,
        "plan": plan,
        "action": "decide"
    }


def decide_node(state: State):
    """å†³ç­–èŠ‚ç‚¹ï¼šå†³å®šä¸‹ä¸€æ­¥è¡ŒåŠ¨"""
    system_prompt = """Based on your thinking and plan, decide what to do next.

Options:
1. "use_tool" - If you need to call a tool (list_directory or read_file_tool)
2. "ask_user" - If you need more information from the user
3. "respond" - If you have enough information to answer the user

Respond with ONLY one word: "use_tool", "ask_user", or "respond"."""
    
    thinking = state.get("thinking", "")
    plan = state.get("plan", "")
    
    decision_prompt = f"""Thinking: {thinking}

Plan: {plan}

What should I do next? Choose one:
- "use_tool" if I need to use a tool
- "ask_user" if I need more information
- "respond" if I can answer now

Decision:"""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=decision_prompt)
    ]
    
    response = llm.invoke(messages)
    decision = response.content.strip().lower()
    
    # æ¸…ç†å†³ç­–æ–‡æœ¬ï¼Œæå–å…³é”®è¯
    if "use_tool" in decision or "tool" in decision:
        decision = "use_tool"
    elif "ask_user" in decision or "ask" in decision or "more" in decision:
        decision = "ask_user"
    else:
        decision = "respond"
    
    print(f"\nğŸ“‹ DECISION: {decision.upper()}\n")
    
    return {
        "action": decision
    }


def act_node(state: State):
    """æ‰§è¡ŒèŠ‚ç‚¹ï¼šè°ƒç”¨å·¥å…·"""
    system_prompt = """You are a professional file-analyzing assistant. You can use the following tools:
1. list_directory: list the content of a dir
2. read_file_tool: read the content of a (text) file

Based on your plan, decide which tool to use and call it."""
    
    messages = [SystemMessage(content=system_prompt)]
    messages.extend(state["messages"])
    
    # æ·»åŠ æ€è€ƒè¿‡ç¨‹åˆ°ä¸Šä¸‹æ–‡
    if state.get("thinking"):
        messages.append(SystemMessage(
            content=f"Your thinking: {state['thinking']}\nYour plan: {state.get('plan', '')}"
        ))
    
    print("\nğŸ”§ ACTING: Calling tool...\n")
    
    response = model_with_tools.invoke(messages)
    
    # æ£€æŸ¥æ˜¯å¦è°ƒç”¨äº†å·¥å…·
    if hasattr(response, 'tool_calls') and response.tool_calls:
        tool_names = [tc['name'] for tc in response.tool_calls]
        print(f"ğŸ“Œ Invoking tools: {', '.join(tool_names)}\n")
    
    return {"messages": [response]}


def observe_node(state: State):
    """è§‚å¯ŸèŠ‚ç‚¹ï¼šæ‰§è¡Œå·¥å…·å¹¶è§‚å¯Ÿç»“æœ"""
    last_message = state["messages"][-1]
    
    if not (hasattr(last_message, 'tool_calls') and last_message.tool_calls):
        return {"messages": []}
    
    print("\nğŸ‘€ OBSERVING: Executing tools...\n")
    
    result = []
    for tool_call in last_message.tool_calls:
        tool = tools_by_name[tool_call["name"]]
        print(f"  â†’ Executing {tool_call['name']} with args: {tool_call['args']}")
        
        try:
            observation = tool.invoke(tool_call["args"])
            print(f"  âœ“ Tool executed successfully\n")
        except Exception as e:
            observation = f"Error: failed to execute tool - {str(e)}"
            print(f"  âœ— Tool execution failed: {e}\n")
        
        result.append(ToolMessage(
            content=str(observation),
            tool_call_id=tool_call["id"]
        ))
    
    return {"messages": result}


def respond_node(state: State):
    """å“åº”èŠ‚ç‚¹ï¼šç”Ÿæˆæœ€ç»ˆå›å¤"""
    system_prompt = """You are a professional file-analyzing assistant. Based on your thinking, plan, and the information you've gathered, provide a clear and helpful answer to the user."""
    
    messages = [SystemMessage(content=system_prompt)]
    messages.extend(state["messages"])
    
    # æ·»åŠ æ€è€ƒè¿‡ç¨‹
    if state.get("thinking"):
        messages.append(SystemMessage(
            content=f"Your thinking process: {state['thinking']}"
        ))
    
    print("\nğŸ’¬ RESPONDING: Generating answer...\n")
    
    response = llm.invoke(messages)
    
    return {"messages": [response]}


def ask_user_node(state: State):
    """è¯¢é—®ç”¨æˆ·èŠ‚ç‚¹ï¼šå‘ç”¨æˆ·è¯·æ±‚æ›´å¤šä¿¡æ¯"""
    system_prompt = """You need more information from the user to complete the task. Ask a clear and specific question."""
    
    thinking = state.get("thinking", "")
    plan = state.get("plan", "")
    
    ask_prompt = f"""Based on your thinking and plan, what information do you need from the user?

Thinking: {thinking}
Plan: {plan}

Ask the user a clear question:"""
    
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=ask_prompt)
    ]
    
    response = llm.invoke(messages)
    
    print("\nâ“ ASKING USER:\n")
    print(response.content)
    print()
    
    return {
        "messages": [response],
        "needs_more_info": True
    }


def should_continue(state: State) -> Literal["act", "respond", "ask_user", END]:
    """è·¯ç”±å‡½æ•°ï¼šæ ¹æ®å†³ç­–å†³å®šä¸‹ä¸€æ­¥"""
    action = state.get("action", "respond")
    
    if action == "use_tool":
        return "act"  # éœ€è¦è°ƒç”¨å·¥å…·
    
    elif action == "ask_user":
        return "ask_user"
    
    elif action == "respond":
        return "respond"
    
    else:
        return END


def should_loop_after_observe(state: State) -> Literal["thinking", END]:
    """è§‚å¯Ÿå·¥å…·ç»“æœåï¼Œåˆ¤æ–­æ˜¯å¦éœ€è¦é‡æ–°æ€è€ƒ"""
    # å·¥å…·æ‰§è¡Œå®Œæˆåï¼Œæ€»æ˜¯é‡æ–°æ€è€ƒä¸‹ä¸€æ­¥
    return "thinking"


def build_graph():
    """æ„å»º Agent å›¾"""
    graph_builder = StateGraph(State)
    
    # æ·»åŠ èŠ‚ç‚¹
    graph_builder.add_node("thinking", thinking_node)
    graph_builder.add_node("decide", decide_node)
    graph_builder.add_node("act", act_node)
    graph_builder.add_node("observe", observe_node)
    graph_builder.add_node("respond", respond_node)
    graph_builder.add_node("ask_user", ask_user_node)
    
    # è®¾ç½®å…¥å£
    graph_builder.add_edge(START, "thinking")
    
    # æ€è€ƒåè¿›å…¥å†³ç­–
    graph_builder.add_edge("thinking", "decide")
    
    # å†³ç­–åæ ¹æ®ç»“æœè·¯ç”±
    graph_builder.add_conditional_edges(
        "decide",
        should_continue,
        {
            "act": "act",
            "observe": "observe",
            "respond": "respond",
            "ask_user": "ask_user",
            END: END
        }
    )
    
    # æ‰§è¡Œå·¥å…·åè§‚å¯Ÿç»“æœ
    graph_builder.add_edge("act", "observe")
    
    # è§‚å¯Ÿåé‡æ–°æ€è€ƒä¸‹ä¸€æ­¥
    graph_builder.add_conditional_edges(
        "observe",
        should_loop_after_observe,
        {
            "thinking": "thinking",  # é‡æ–°æ€è€ƒ
            END: END
        }
    )
    
    # å“åº”å’Œè¯¢é—®ç”¨æˆ·åç»“æŸ
    graph_builder.add_edge("respond", END)
    graph_builder.add_edge("ask_user", END)
    
    # ä½¿ç”¨ checkpoint æ”¯æŒè®°å¿†
    checkpointer = MemorySaver()
    
    return graph_builder.compile(checkpointer=checkpointer)


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ¤– Smart File Helper (with Thinking & Planning)")
    print("=" * 60)
    print(f"\nCurrent working directory: {os.getcwd()}")
    print("You can ask me to analyze files, list directories, etc.\n")
    print("Type 'quit' or 'exit' to quit.\n")
    
    # æ„å»ºå›¾
    graph = build_graph()
    
    # ä½¿ç”¨ checkpoint ç®¡ç†å¯¹è¯çŠ¶æ€
    thread_id = "chat-boy-session"
    config = {"configurable": {"thread_id": thread_id}}
    
    # äº¤äº’å¼å¾ªç¯
    while True:
        try:
            user_input = input("User> ").strip()
            
            if not user_input:
                continue
            
            if user_input.lower() in ["quit", "exit", "q"]:
                print("\nBye! ğŸ‘‹\n")
                break
            
            # å‡†å¤‡è¾“å…¥ï¼ˆåªä¼ å…¥æ–°æ¶ˆæ¯ï¼Œcheckpoint ä¼šè‡ªåŠ¨ç»´æŠ¤å†å²çŠ¶æ€ï¼‰
            inputs = {
                "messages": [HumanMessage(content=user_input)],
                "thinking": "",
                "plan": "",
                "action": None,
                "needs_more_info": False
            }
            
            # æ‰§è¡Œå›¾ï¼ˆcheckpoint ä¼šè‡ªåŠ¨ä¿å­˜å’Œæ¢å¤çŠ¶æ€ï¼‰
            result = graph.invoke(inputs, config=config)
            
            # æ˜¾ç¤ºæœ€ç»ˆå›å¤
            if result.get("messages"):
                last_message = result["messages"][-1]
                if isinstance(last_message, AIMessage):
                    print("\n" + "="*60)
                    print("ğŸ¤– ASSISTANT:")
                    print("="*60)
                    print(last_message.content)
                    print("="*60 + "\n")
            
        except KeyboardInterrupt:
            print("\n\nBye! ğŸ‘‹\n")
            break
        except Exception as e:
            print(f"\nâŒ Error: {e}\n")
            import traceback
            traceback.print_exc()


if __name__ == "__main__":
    main()

